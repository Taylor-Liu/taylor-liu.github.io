---
layout: page
title:  NLP
---

---
**Table of Contents**
* TOC
{:toc}
---

### Blog

- [Generalized Language Models (Lil'Log)](https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html)

[张俊林](https://www.zhihu.com/people/zhang-jun-lin-76/posts)
- [从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史](https://zhuanlan.zhihu.com/p/49271699)
- [放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941)
- [效果惊人的GPT 2.0模型：它告诉了我们什么](https://zhuanlan.zhihu.com/p/56865533)
- [Bert时代的创新：Bert应用模式比较及其它](https://zhuanlan.zhihu.com/p/65470719)
- [Bert时代的创新（应用篇）：Bert在NLP各领域的应用进展](https://zhuanlan.zhihu.com/p/68446772)
- [XLNet:运行机制及和Bert的异同比较](https://zhuanlan.zhihu.com/p/70257427)

### Topics

注意力机制
- [深度学习中的注意力模型（2017版）](https://zhuanlan.zhihu.com/p/37601161)

### Github

- [CyberZHG/keras-bert](https://github.com/CyberZHG/keras-bert)
	- Implementation of BERT that could load official pre-trained models for feature extraction and prediction

### Talk

将门分享14-刘洋-基于深度学习的机器翻译update.pdf

### Course

- Stanford, Winter 2019
	- [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/index.html)
- CMU CS 11-747, Spring 2019
	- [Neural Networks for NLP](http://phontron.com/class/nn4nlp2019/#)

